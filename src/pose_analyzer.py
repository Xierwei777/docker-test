import cv2
import mediapipe as mp
import numpy as np
from typing import List, Tuple, Dict, Optional
import tensorflow as tf
from src.pose import KeyPointClassifier
import time
# import copy  # ğŸ”¥ ä¼˜åŒ–ï¼šç§»é™¤copyæ¨¡å—ï¼Œä½¿ç”¨numpy.copyæ›´å¿«
import os
from datetime import datetime
from src.pose_logger import PoseLogger
class PoseAnalyzer:
    def __init__(self, model_complexity=1, enable_gpu=True, enable_logging=True, console_output=True, record_interval=1.0):
        """
        åˆå§‹åŒ–å§¿æ€åˆ†æå™¨
        
        Args:
            model_complexity: æ¨¡å‹å¤æ‚åº¦
                0 = Lite (æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½)
                1 = Full (å¹³è¡¡ï¼Œæ¨è) 
                2 = Heavy (æœ€æ…¢ï¼Œç²¾åº¦æœ€é«˜)
            enable_gpu: æ˜¯å¦å¯ç”¨GPUåŠ é€Ÿ
            enable_logging: æ˜¯å¦å¯ç”¨æ—¥å¿—è®°å½•
            console_output: æ˜¯å¦åœ¨æ§åˆ¶å°æ‰“å°æ£€æµ‹è®°å½•ï¼ˆæ‰“å°å°é£æ ¼ï¼‰
            record_interval: æ—¥å¿—è®°å½•é—´éš”ï¼ˆç§’ï¼‰ï¼Œä¸å½±å“è§†é¢‘å¸§ç‡
        """
        # é…ç½® GPU
        if enable_gpu:
            self._configure_gpu()
        
        # åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        self.logger = PoseLogger(console_output=console_output, record_interval=record_interval) if enable_logging else None
        self.enable_logging = enable_logging
        
        # åˆå§‹åŒ–MediaPipeå§¿æ€æ£€æµ‹
        self.mp_pose = mp.solutions.pose
        try:
            self.pose = self.mp_pose.Pose(
                static_image_mode=False,
                model_complexity=model_complexity,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            )
            print(f"[OK] MediaPipe Pose initialized (model complexity: {model_complexity})")
        except Exception as e:
            print(f"[ERROR] Failed to initialize MediaPipe: {e}")
            print("[TIP] Trying Lite model (model_complexity=0)")
            # é™çº§åˆ° Lite æ¨¡å‹
            self.pose = self.mp_pose.Pose(
                static_image_mode=False,
                model_complexity=0,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5
            )
            print("[OK] Downgraded to Lite model")
        self.mp_drawing = mp.solutions.drawing_utils
        
        # åˆå§‹åŒ–å§¿æ€åˆ†ç±»å™¨ï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼‰
        try:
            self.classifier = KeyPointClassifier()
            print("[OK] Pose classifier initialized")
        except Exception as e:
            print(f"[ERROR] Failed to initialize pose classifier: {e}")
            self.classifier = None
        
        # å§¿æ€ç±»åˆ«å®šä¹‰
        self.dir=['standing','Sit','stoop','lying','kneel']

        # æ·»åŠ ç»˜åˆ¶ç›¸å…³å±æ€§
        self.current_pose = None
        self.last_pose = None
        self.pose_count = 0
        self.pose_start_time = None
        self.use_brect = True
    
    def _configure_gpu(self):
        """é…ç½® GPU åŠ é€Ÿï¼ˆæ”¯æŒåŒæ˜¾å¡ç¬”è®°æœ¬ï¼‰"""
        try:
            # æ·»åŠ  CUDA DLL è·¯å¾„ï¼ˆWindowsï¼‰
            if os.name == 'nt':  # Windows
                cuda_paths = [
                    'C:/Program Files/NVIDIA/cuda/bin',
                    'C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/bin',
                ]
                for path in cuda_paths:
                    if os.path.exists(path):
                        try:
                            os.add_dll_directory(path)
                            print(f"[GPU] å·²æ·»åŠ  DLL è·¯å¾„: {path}")
                        except Exception as e:
                            pass
            
            # æ£€æµ‹æ‰€æœ‰ GPU
            all_gpus = tf.config.list_physical_devices('GPU')
            
            if all_gpus:
                print(f"[GPU] Detected {len(all_gpus)} GPU device(s):")
                for i, gpu in enumerate(all_gpus):
                    print(f"[GPU] GPU {i}: {gpu.name}")
                
                # è¿‡æ»¤å‡º NVIDIA GPUï¼ˆè·³è¿‡ Intel æ ¸æ˜¾ï¼‰
                # Intel GPU é€šå¸¸åŒ…å« "Intel" æˆ– "HD Graphics"
                # NVIDIA GPU é€šå¸¸åŒ…å« "NVIDIA" æˆ– "GeForce"
                nvidia_gpus = []
                for i, gpu in enumerate(all_gpus):
                    gpu_name = gpu.name.lower()
                    # è·³è¿‡ Intel æ ¸æ˜¾
                    if 'intel' in gpu_name or 'hd graphics' in gpu_name:
                        print(f"[GPU] Skipping GPU {i} (Intel integrated)")
                        continue
                    # ä½¿ç”¨ NVIDIA GPU
                    nvidia_gpus.append(gpu)
                    print(f"[GPU] Selected GPU {i} (NVIDIA discrete) [OK]")
                
                if nvidia_gpus:
                    # ä¸º NVIDIA GPU å¯ç”¨å†…å­˜å¢é•¿
                    for gpu in nvidia_gpus:
                        try:
                            tf.config.experimental.set_memory_growth(gpu, True)
                        except RuntimeError as e:
                            print(f"[GPU] Memory configuration failed: {e}")
                    
                    # åªè®¾ç½® NVIDIA GPU ä¸ºå¯è§è®¾å¤‡
                    tf.config.set_visible_devices(nvidia_gpus, 'GPU')
                    
                    print(f"[GPU] Enabled {len(nvidia_gpus)} NVIDIA GPU(s)")
                    
                    # è®¾ç½® TensorFlow æ—¥å¿—çº§åˆ«
                    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
                    
                else:
                    print("[GPU] No NVIDIA GPU detected, using CPU mode")
                    # CPU ä¼˜åŒ–
                    tf.config.threading.set_intra_op_parallelism_threads(4)
                    tf.config.threading.set_inter_op_parallelism_threads(4)
                
            else:
                print("[GPU] No GPU detected, using CPU mode")
                # CPU ä¼˜åŒ–
                tf.config.threading.set_intra_op_parallelism_threads(4)
                tf.config.threading.set_inter_op_parallelism_threads(4)
                
        except Exception as e:
            print(f"[GPU] Configuration failed: {e}")
            print("[GPU] Using CPU mode")
            # CPU ä¼˜åŒ–ä½œä¸ºåå¤‡æ–¹æ¡ˆ
            try:
                tf.config.threading.set_intra_op_parallelism_threads(4)
                tf.config.threading.set_inter_op_parallelism_threads(4)
            except:
                pass
    
    def process_frame(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict]:
        """
        å¤„ç†å•å¸§å›¾åƒï¼Œè¿”å›å¸¦æœ‰å§¿æ€æ ‡æ³¨çš„å›¾åƒå’Œå§¿æ€æ•°æ®
        """
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = time.time()
        datetime_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        
        # è½¬æ¢é¢œè‰²ç©ºé—´
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(image_rgb)
        # ğŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨numpy.copyæ›¿ä»£copy.deepcopyï¼Œé€Ÿåº¦å¿«3-5å€
        debug_image = frame.copy()

        # æå–å…³é”®ç‚¹
        pose_landmarks = []
        pose_result = None
        has_target = False
        confidence = 0.0

        if results.pose_landmarks:
            has_target = True
            for landmark in results.pose_landmarks.landmark:
                pose_landmarks.append([landmark.x, landmark.y])

            # è®¡ç®—è¾¹ç•Œæ¡†
            brect = self.calc_bounding_rect(debug_image, pose_landmarks)
            # é¢„å¤„ç†å…³é”®ç‚¹ç”¨äºå§¿æ€åˆ†æ
            pose_landmarks_flat = [landmark[i] for landmark in pose_landmarks for i in range(2)]
            pose_result = self.analyze_pose_sequence(pose_landmarks_flat)
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºå…³é”®ç‚¹çš„å¯è§æ€§ï¼‰
            confidence = sum([lm.visibility for lm in results.pose_landmarks.landmark]) / len(results.pose_landmarks.landmark)

            # ç»˜åˆ¶éƒ¨åˆ† - ä½¿ç”¨å‚è€ƒæ–‡ä»¶çš„ç»˜åˆ¶æ–¹æ³•
            debug_image = self.draw_bounding_rect(self.use_brect, debug_image, brect)
            self.mp_drawing.draw_landmarks(
                debug_image,
                results.pose_landmarks,
                self.mp_pose.POSE_CONNECTIONS
            )
            debug_image = self.draw_pose_info_text(debug_image, brect, pose_result)
        else:
            # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡
            debug_image = self.draw_no_target_info(debug_image)
        
        # æ„å»ºåˆ†æç»“æœ
        analysis_result = {
            'timestamp': timestamp,
            'datetime': datetime_str,
            'landmarks': pose_landmarks,
            'pose': pose_result if pose_result else 'No Target',
            'has_target': has_target,
            'landmarks_count': len(pose_landmarks),
            'confidence': round(confidence, 3),
            'note': 'æ­£å¸¸æ£€æµ‹' if has_target else 'æœªæ£€æµ‹åˆ°ç›®æ ‡'
        }
        
        # è®°å½•åˆ†æç»“æœ
        if self.enable_logging and self.logger:
            self.logger.log_analysis(analysis_result)
        
        return debug_image, analysis_result
    
    def draw_bounding_rect(self, use_brect, image, brect):
        if use_brect:
            # å¤–æ¥çŸ©å½¢
            cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]), (0, 0, 0), 1)

        return image
    #è®¡ç®—è¾¹æ¡†
    def calc_bounding_rect(self, image, landmarks):
        image_width, image_height = image.shape[1], image.shape[0]
        landmark_array = np.empty((0, 2), int)

        for _, landmark in enumerate(landmarks):
            landmark_x = min(int(landmark[0] * image_width), image_width - 1)
            landmark_y = min(int(landmark[1] * image_height), image_height - 1)
            landmark_point = [np.array((landmark_x, landmark_y))]
            landmark_array = np.append(landmark_array, landmark_point, axis=0)

        x, y, w, h = cv2.boundingRect(landmark_array)
        return [x, y, x + w, y + h]

    def analyze_pose_sequence(self, landmarks_sequence: List[List[float]]) -> str:
        """
        åˆ†æå§¿æ€åºåˆ—ï¼Œè¯†åˆ«åŠ¨ä½œç±»å‹
        """
        if self.classifier is None:
            return "Unknown"
        
        try:
            result_index = self.classifier(landmarks_sequence)
            return self.dir[result_index]
        except Exception as e:
            print(f"[ERROR] Pose classification failed: {e}")
            return "Unknown"

    def draw_pose_info_text(self, image, brect, pose_text):
        """ç»˜åˆ¶å§¿æ€ä¿¡æ¯æ–‡æœ¬"""
        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22), (0, 0, 0), -1)

        info_text = f"Pose: {pose_text}" if pose_text else "Pose: Unknown"

        # æ›´æ–°å½“å‰å§¿æ€
        if self.current_pose != pose_text:
            self.last_pose = self.current_pose
            self.current_pose = pose_text
            self.pose_count = 1
            self.pose_start_time = time.time()
        else:
            self.pose_count += 1

        cv2.putText(image, info_text, (brect[0] + 5, brect[1] - 4),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)

        # å·¦ä¸Šè§’è¯¦ç»†æ•°æ®å·²ç§»é™¤ï¼ˆç”¨æˆ·ä¸éœ€è¦ï¼‰
        # - Durationï¼ˆæŒç»­æ—¶é—´ï¼‰
        # - Timeï¼ˆæ—¶é—´æˆ³ï¼‰
        # è¿™äº›æ•°æ®ä»ä¼šåœ¨æ—¥å¿—ç›‘æ§ä¸­æ˜¾ç¤º

        return image
    
    def draw_no_target_info(self, image):
        """å½“æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡æ—¶æ˜¾ç¤ºæç¤ºä¿¡æ¯"""
        height, width = image.shape[:2]
        
        # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (width, 100), (0, 0, 0), -1)
        image = cv2.addWeighted(overlay, 0.5, image, 0.5, 0)
        
        # æ˜¾ç¤º"æ— ç›®æ ‡"æç¤º
        no_target_text = "No Target Detected"
        no_target_text_cn = "æœªæ£€æµ‹åˆ°ç›®æ ‡"
        
        cv2.putText(image, no_target_text, (width // 2 - 150, 40),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3, cv2.LINE_AA)
        cv2.putText(image, no_target_text, (width // 2 - 150, 40),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2, cv2.LINE_AA)
        
        # ä¸­æ–‡æç¤ºï¼ˆä½¿ç”¨ç®€å•ç¬¦å·ä»£æ›¿ï¼Œå› ä¸ºOpenCVä¸­æ–‡æ˜¾ç¤ºè¾ƒå¤æ‚ï¼‰
        hint_text = "Please stand in front of the camera"
        cv2.putText(image, hint_text, (width // 2 - 200, 75),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
        
        # å·¦ä¸Šè§’æ—¶é—´æˆ³å·²ç§»é™¤ï¼ˆç”¨æˆ·ä¸éœ€è¦ï¼‰
        
        return image

    def draw_pose_landmarks(self, image, landmarks):
        """ç»˜åˆ¶å§¿æ€å…³é”®ç‚¹"""
        if not landmarks:
            return image
        
        # ç»˜åˆ¶å…³é”®ç‚¹
        for landmark in landmarks:
            if len(landmark) >= 2:
                x, y = int(landmark[0]), int(landmark[1])
                cv2.circle(image, (x, y), 3, (0, 255, 0), -1)
        
        return image

    def start_realtime_analysis(self):
        """
        å¯åŠ¨å®æ—¶å§¿æ€åˆ†æ
        """
        cap=cv2.VideoCapture(0)
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.flip(frame, 1)
            height, width = frame.shape[:2]
            display_width = 1080
            display_height = int(height * display_width / width)

            frame = cv2.resize(frame, (display_width, display_height))
            # å¤„ç†å¸§
            processed_frame, analysis_data = self.process_frame(frame)

            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('Pose Analysis', processed_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    analyzer = PoseAnalyzer()
    analyzer.start_realtime_analysis()